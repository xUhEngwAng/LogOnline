{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b70f3d-9bc9-40ae-aabd-dfbac82bcc55",
   "metadata": {},
   "source": [
    "## BGL data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03edb9fa-14bf-46b5-862a-c66a9010d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BGL_log_path = '../data/BGL/BGL.log'\n",
    "assert(os.path.isfile(BGL_log_path))\n",
    "\n",
    "BGL_parsed_path = '../data/BGL/BGL_parsed_result_level_03.csv'\n",
    "assert(os.path.isfile(BGL_parsed_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ef95c7-8ba4-4e05-8686-33baa61709db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(BGL_log_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m log_line \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadlines():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# remove header & \\n at the end of each line\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m         log_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mlog_line\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         components\u001b[38;5;241m.\u001b[39mappend(log_tokens[\u001b[38;5;241m7\u001b[39m])\n\u001b[1;32m      9\u001b[0m         timestamps\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(log_tokens[\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "components, timestamps = [], []\n",
    "\n",
    "with open(BGL_log_path) as f:\n",
    "    for log_line in f.readlines():\n",
    "        # remove header & \\n at the end of each line\n",
    "        log_tokens = log_line.split()\n",
    "        \n",
    "        components.append(log_tokens[7])\n",
    "        timestamps.append(int(log_tokens[1]))\n",
    "        \n",
    "time_elapsed = [0]\n",
    "time_elapsed.extend([timestamps[ind] - timestamps[ind-1] for ind in range(1, len(timestamps))])\n",
    "\n",
    "parsed_log_df = pd.read_csv(BGL_parsed_path)\n",
    "parsed_log_df['Component'] = components\n",
    "parsed_log_df['Timestamp'] = timestamps\n",
    "parsed_log_df['TimeElapsed'] = time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a23cc56-ce51-42bb-9052-e8c82c184beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Templates</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>LogMessage</th>\n",
       "      <th>Anomaly</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Session</th>\n",
       "      <th>Level</th>\n",
       "      <th>Component</th>\n",
       "      <th>TimeElapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1750000</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>False</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750000</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>False</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1750000</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>False</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1750000</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>False</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1750000</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>[]</td>\n",
       "      <td>instruction cache parity error corrected</td>\n",
       "      <td>False</td>\n",
       "      <td>1117838570</td>\n",
       "      <td>R02-M1-N0-C:J12-U11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>KERNEL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId                                 Templates Parameters  \\\n",
       "0  1750000  instruction cache parity error corrected         []   \n",
       "1  1750000  instruction cache parity error corrected         []   \n",
       "2  1750000  instruction cache parity error corrected         []   \n",
       "3  1750000  instruction cache parity error corrected         []   \n",
       "4  1750000  instruction cache parity error corrected         []   \n",
       "\n",
       "                                 LogMessage  Anomaly   Timestamp  \\\n",
       "0  instruction cache parity error corrected    False  1117838570   \n",
       "1  instruction cache parity error corrected    False  1117838570   \n",
       "2  instruction cache parity error corrected    False  1117838570   \n",
       "3  instruction cache parity error corrected    False  1117838570   \n",
       "4  instruction cache parity error corrected    False  1117838570   \n",
       "\n",
       "               Session Level Component  TimeElapsed  \n",
       "0  R02-M1-N0-C:J12-U11  INFO    KERNEL            0  \n",
       "1  R02-M1-N0-C:J12-U11  INFO    KERNEL            0  \n",
       "2  R02-M1-N0-C:J12-U11  INFO    KERNEL            0  \n",
       "3  R02-M1-N0-C:J12-U11  INFO    KERNEL            0  \n",
       "4  R02-M1-N0-C:J12-U11  INFO    KERNEL            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3c12529-4707-4f6e-b9e7-e4becfc37d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_log_df.to_csv('../data/BGL/BGL_parsed_result_full_03.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1eee8-4347-44d3-8183-840505428a30",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8754e32b-0934-4aeb-92aa-e115ce621c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = 'BGL'\n",
    "parsed_path = '../data/{}/{}.log_structured.csv'.format(dataset, dataset)\n",
    "parsed_log_df = pd.read_csv(parsed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc09b09-0180-4bf0-9cca-9d49125c9487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxuheng/Downloads/miniconda3/envs/UniLog/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from dataset import LogDataset\n",
    "from partition import partition\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c765b2-fe8e-4072-8294-89d02d75aebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 20:33:55,758 - INFO - filter_abnormal enabled when creating training data.\n",
      "2023-03-20 20:34:07,698 - INFO - Training sessions generated, mean = 1.1978604769583299, stddev = 81.32467272087531.\n",
      "2023-03-20 20:34:14,384 - INFO - partitionByOrder done, 22066 sessions are generated.\n",
      "2023-03-20 20:34:14,385 - INFO - Sequential Partitioning done. 1653 event ids are identified.\n",
      "2023-03-20 20:34:14,386 - INFO - Number of training and testing sessions are 11783 and 10283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of componens: 9, number of training events: 183, number of levels: 6.\n"
     ]
    }
   ],
   "source": [
    "session_train, session_test, num_components, num_classes, num_levels, level2ind = partition(parsed_log_df, \n",
    "                                                                                            'timestamp', \n",
    "                                                                                             0.5, \n",
    "                                                                                             True,\n",
    "                                                                                             200,\n",
    "                                                                                             False)\n",
    "\n",
    "print(f'Number of componens: {num_components}, number of training events: {num_classes}, number of levels: {num_levels}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d449645-2e02-468f-8b16-e0302c3a1fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "eval_batch_size = 1024\n",
    "step_size = 1\n",
    "window_size = 10\n",
    "\n",
    "dataset_train = LogDataset(session_train, \n",
    "                           window_size, \n",
    "                           step_size, \n",
    "                           num_classes)\n",
    "\n",
    "dataset_test = LogDataset(session_test, \n",
    "                          window_size, \n",
    "                          step_size, \n",
    "                          num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6efd071f-7158-4b57-b9e1-94874aeae88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch_input_dict):\n",
    "    keys = [input_dict['session_key'] for input_dict in batch_input_dict]\n",
    "    templates = [input_dict['templates'] for input_dict in batch_input_dict]\n",
    "    event_ids = [input_dict['eventids'] for input_dict in batch_input_dict]\n",
    "    time_elapsed = [input_dict['time_elapsed'] for input_dict in batch_input_dict]\n",
    "    components = [input_dict['components'] for input_dict in batch_input_dict]\n",
    "    levels = [input_dict['levels'] for input_dict in batch_input_dict]\n",
    "    \n",
    "    next_logs = [input_dict['next'] for input_dict in batch_input_dict]\n",
    "    anomaly = [input_dict['anomaly'] for input_dict in batch_input_dict]\n",
    "\n",
    "    return {'session_key': keys,\n",
    "            'templates': templates,\n",
    "            'eventids': event_ids,\n",
    "            'time_elapsed': time_elapsed,\n",
    "            'components': components,\n",
    "            'levels': levels,\n",
    "            'next': next_logs,\n",
    "            'anomaly': anomaly}\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              collate_fn=collate_fn, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=False, \n",
    "                              pin_memory=False)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, \n",
    "                             collate_fn=collate_fn, \n",
    "                             batch_size=eval_batch_size, \n",
    "                             shuffle=False, \n",
    "                             pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89060e-2f64-4d55-8f21-70cb688c729f",
   "metadata": {},
   "source": [
    "## Training autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae4e9e0-8d6a-4b62-b26f-97936de20874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_components, num_levels):\n",
    "        super(AutoEncoderEmbedding, self).__init__()\n",
    "        self.num_components = num_components\n",
    "        self.num_levels = num_levels\n",
    "        \n",
    "        components_embedding = torch.vstack([torch.eye(num_components), torch.zeros(1, num_components)])\n",
    "        levels_embedding = torch.vstack([torch.eye(num_levels), torch.zeros(1, num_levels)])\n",
    "        self.component_embedder = torch.nn.Embedding.from_pretrained(components_embedding, freeze=True)\n",
    "        self.level_embedder = torch.nn.Embedding.from_pretrained(levels_embedding, freeze=True)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        components = torch.tensor(input_dict['components'])\n",
    "        levels = torch.tensor(input_dict['levels'])\n",
    "        time_elapsed = torch.tensor(input_dict['time_elapsed']).unsqueeze(-1).cuda()\n",
    "        \n",
    "        components[self.num_components < components] = self.num_components\n",
    "        levels[self.num_levels < levels] = self.num_levels\n",
    "        \n",
    "        components_embedding = self.component_embedder(components.cuda())\n",
    "        levels_embedding = self.level_embedder(levels.cuda())\n",
    "        return torch.cat([time_elapsed, components_embedding, levels_embedding], dim=2)\n",
    "\n",
    "class AutoEncoder(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_components,\n",
    "                 num_levels,\n",
    "                 window_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.EmbeddingLayer = AutoEncoderEmbedding(num_components, num_levels)\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(window_size * (num_components+num_levels+1), 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 12),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(12, 3)\n",
    "        )\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3, 12),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(12, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, window_size * (num_components+num_levels+1)),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        embedding_matrix = self.EmbeddingLayer(input_dict)\n",
    "        embedding = embedding_matrix.view(embedding_matrix.size(0), -1)\n",
    "        encoding = self.encoder(embedding)\n",
    "        return embedding, self.decoder(encoding)\n",
    "    \n",
    "class VariationalAutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_components,\n",
    "                 num_levels,\n",
    "                 window_size):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "        self.EmbeddingLayer = AutoEncoderEmbedding(num_components, num_levels)\n",
    "        self.fc1 = torch.nn.Linear(window_size * (num_components+num_levels+1), 100)\n",
    "        self.fc21 = torch.nn.Linear(100, 10)\n",
    "        self.fc22 = torch.nn.Linear(100, 10)\n",
    "        self.fc3 = torch.nn.Linear(10, 100)\n",
    "        self.fc4 = torch.nn.Linear(100, window_size * (num_components+num_levels+1))\n",
    "        \n",
    "    def encode(self, embedding):\n",
    "        h1 = torch.nn.functional.relu(self.fc1(embedding))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = torch.autograd.Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = torch.nn.functional.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        embedding_matrix = self.EmbeddingLayer(input_dict)\n",
    "        embedding = embedding_matrix.view(embedding_matrix.size(0), -1)\n",
    "        \n",
    "        mu, logvar = self.encode(embedding)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return embedding, self.decode(z), mu, logvar\n",
    "    \n",
    "reconstruction_function = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    BCE = reconstruction_function(recon_x, x)  # mse loss\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c65b2271-aaf0-4073-b441-ae2790e3dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1|10] Training finished, training loss: 0.066.\n",
      "[1|10] Evaluation done, FP: 35, precision:  1.000, recall: 0.790, F1-measure:  0.883.\n",
      "[2|10] Training finished, training loss: 0.065.\n",
      "[2|10] Evaluation done, FP: 37, precision:  1.000, recall: 0.791, F1-measure:  0.883.\n",
      "[3|10] Training finished, training loss: 0.065.\n",
      "[3|10] Evaluation done, FP: 42617, precision:  0.974, recall: 0.865, F1-measure:  0.916.\n",
      "[4|10] Training finished, training loss: 0.064.\n",
      "[4|10] Evaluation done, FP: 42623, precision:  0.974, recall: 0.865, F1-measure:  0.917.\n",
      "[5|10] Training finished, training loss: 0.064.\n",
      "[5|10] Evaluation done, FP: 42681, precision:  0.974, recall: 0.866, F1-measure:  0.917.\n",
      "[6|10] Training finished, training loss: 0.064.\n",
      "[6|10] Evaluation done, FP: 42660, precision:  0.974, recall: 0.866, F1-measure:  0.917.\n",
      "[7|10] Training finished, training loss: 0.064.\n",
      "[7|10] Evaluation done, FP: 42625, precision:  0.974, recall: 0.866, F1-measure:  0.917.\n",
      "[8|10] Training finished, training loss: 0.064.\n",
      "[8|10] Evaluation done, FP: 97387, precision:  0.943, recall: 0.875, F1-measure:  0.908.\n",
      "[9|10] Training finished, training loss: 0.064.\n",
      "[9|10] Evaluation done, FP: 97346, precision:  0.943, recall: 0.875, F1-measure:  0.908.\n",
      "[10|10] Training finished, training loss: 0.064.\n",
      "[10|10] Evaluation done, FP: 42975, precision:  0.974, recall: 0.867, F1-measure:  0.917.\n"
     ]
    }
   ],
   "source": [
    "batch_cnt = 0\n",
    "learning_rate = 2e-3\n",
    "num_epochs = 10\n",
    "total_loss = 0\n",
    "thresh = 0.02\n",
    "# training_losses = []\n",
    "\n",
    "model = AutoEncoder(num_components, num_levels, window_size+1).cuda()\n",
    "# model.load_state_dict(torch.load('../checkpoint/bgl_ae_08_epoch10.pth'))\n",
    "criterion = torch.nn.MSELoss()\n",
    "# model = VariationalAutoEncoder(num_components, num_levels, window_size+1).cuda()\n",
    "# criterion = loss_function\n",
    "\n",
    "eval_criterion = torch.nn.MSELoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in dataloader_train:\n",
    "        batch_cnt += 1\n",
    "        \n",
    "        batch_embedding, output = model(batch)\n",
    "        batch_loss = criterion(output, batch_embedding)\n",
    "        # batch_embedding, output, mu, logvar = model(batch)\n",
    "        # batch_loss = criterion(output, batch_embedding, mu, logvar)\n",
    "        \n",
    "        total_loss += batch_loss.mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'[{epoch+1}|{num_epochs}] Training finished, training loss: {total_loss/batch_cnt :.3f}.')\n",
    "    \n",
    "    TOP = 0\n",
    "    TON = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    for batch in dataloader_test:\n",
    "        batch_size = len(batch['anomaly'])\n",
    "        batch_embedding, output = model(batch)\n",
    "        # batch_embedding, output, mu, logvar = model(batch)\n",
    "        batch_loss = eval_criterion(output, batch_embedding).mean(axis=1)\n",
    "\n",
    "        pred = torch.lt(batch_loss, thresh).tolist()\n",
    "        is_anomaly = batch['anomaly']\n",
    "        TOP += batch_size - sum(is_anomaly)\n",
    "\n",
    "        for ind in range(batch_size):\n",
    "            if pred[ind]:\n",
    "                if is_anomaly[ind]:\n",
    "                    FP += 1\n",
    "                else:\n",
    "                    TP += 1\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / TOP\n",
    "        F1 = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "    print(f'[{epoch+1}|{num_epochs}] Evaluation done, FP: {FP}, precision: {precision: .3f}, recall: {recall :.3f}, F1-measure: {F1: .3f}.')\n",
    "    torch.save(model.state_dict(), f'../checkpoint/tmp/bgl_ae_05_epoch{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "543bdfa9-ecef-468a-a036-88489b070d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='none')\n",
    "training_losses = []\n",
    "\n",
    "for batch in dataloader_train:\n",
    "    batch_cnt += 1\n",
    "    batch_embedding, output = model(batch)\n",
    "    batch_loss = criterion(output, batch_embedding).mean(axis=1).tolist()\n",
    "    \n",
    "    training_losses.extend(batch_loss)\n",
    "\n",
    "assert(len(training_losses) == len(dataset_train))\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(training_losses)\n",
    "# plt.show()\n",
    "\n",
    "# Fit a Gaussion distribution on training losses\n",
    "import statistics\n",
    "mean = statistics.mean(training_losses)\n",
    "stddev = statistics.stdev(training_losses)\n",
    "print(f'mean = {mean}, standard deviation = {stddev}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08d2d785-5f43-49f5-bf43-f3faf5b3cde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation finished, evaluation loss: 0.269.\n"
     ]
    }
   ],
   "source": [
    "batch_cnt = 0\n",
    "# normal_cnt = 0\n",
    "# anomaly_cnt = 0\n",
    "total_loss = 0\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "for batch in dataloader_test:\n",
    "    batch_cnt += 1\n",
    "    batch_embedding, output = model(batch)\n",
    "    batch_loss = criterion(output, batch_embedding).mean(axis=1).tolist()\n",
    "    \n",
    "print(f'Evaluation finished, evaluation loss: {total_loss/batch_cnt :.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d8533ae-ce68-4fae-bbbb-d510400e5355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'INFO': 0, 'FATAL': 1, 'WARNING': 2, 'SEVERE': 3, 'ERROR': 4, 'Kill': 5, 'FAILURE': 6, 'single': 7, 'microseconds': 8, '0x00544eb8,': 9}\n"
     ]
    }
   ],
   "source": [
    "print(level2ind)\n",
    "ind2level = {ind:level for level, ind in level2ind.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d1ad5f-8ad6-488a-94ed-7b0122a40ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'INFO',\n",
       " 1: 'FATAL',\n",
       " 2: 'WARNING',\n",
       " 3: 'SEVERE',\n",
       " 4: 'ERROR',\n",
       " 5: 'Kill',\n",
       " 6: 'FAILURE',\n",
       " 7: 'single',\n",
       " 8: 'microseconds',\n",
       " 9: '0x00544eb8,'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00c22388-3c32-43c8-93eb-5a61471aad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  1.000, Recall: 0.913, F1-measure:  0.955.\n"
     ]
    }
   ],
   "source": [
    "# Directly use LEVEL to determine whether an instance is normal\n",
    "\n",
    "TOP = 0\n",
    "TON = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "for batch in dataloader_test:\n",
    "    batch_size = len(batch['anomaly'])\n",
    "    is_anomaly = batch['anomaly']\n",
    "    batch_levels = [batch['levels'][ind][-1] for ind in range(batch_size)]\n",
    "    \n",
    "    TOP += batch_size - sum(is_anomaly)\n",
    "    \n",
    "    for ind in range(batch_size):\n",
    "        level = ind2level.get(batch_levels[ind], 'UNKNOWN')\n",
    "        if level != 'FATAL' and level != 'ERROR': # predicted as normal\n",
    "            if is_anomaly[ind]:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TP += 1\n",
    "    \n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / TOP\n",
    "F1 = 2 * precision * recall / (precision + recall)\n",
    "print(f'Precision: {precision: .3f}, Recall: {recall :.3f}, F1-measure: {F1: .3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c623d5b1-f29e-4a7c-9295-eb64df0cf135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9436136336414951"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP / len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bc1db93-2731-4a1a-ba89-4277a0fedda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP: 937, Precision:  0.999, Recall: 0.799, F1-measure:  0.888.\n"
     ]
    }
   ],
   "source": [
    "TOP = 0\n",
    "TON = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "model = AutoEncoder(num_components, num_levels, window_size+1).cuda()\n",
    "model.load_state_dict(torch.load('../checkpoint/tmp/bgl_ae_05_epoch2.pth'))\n",
    "# model.load_state_dict(torch.load('../model/autoencoder_10.pth'))\n",
    "model.eval()\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='none')\n",
    "thresh = 0.06\n",
    "\n",
    "for batch in dataloader_test:\n",
    "    batch_size = len(batch['anomaly'])\n",
    "    batch_embedding, output = model(batch)\n",
    "    batch_loss = criterion(output, batch_embedding).mean(axis=1)\n",
    "    \n",
    "    pred = torch.lt(batch_loss, thresh).tolist()\n",
    "    is_anomaly = batch['anomaly']\n",
    "    TOP += batch_size - sum(is_anomaly)\n",
    "    \n",
    "    for ind in range(batch_size):\n",
    "        if pred[ind]:\n",
    "            if is_anomaly[ind]:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TP += 1\n",
    "    \n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / TOP\n",
    "F1 = 2 * precision * recall / (precision + recall)\n",
    "print(f'FP: {FP}, Precision: {precision: .3f}, Recall: {recall :.3f}, F1-measure: {F1: .3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046de30-1d46-415d-880d-00523d8bb69d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AutoEncoder:\n\tsize mismatch for EmbeddingLayer.component_embedder.weight: copying a param with shape torch.Size([8, 7]) from checkpoint, the shape in current model is torch.Size([12, 11]).\n\tsize mismatch for EmbeddingLayer.level_embedder.weight: copying a param with shape torch.Size([3, 2]) from checkpoint, the shape in current model is torch.Size([8, 7]).\n\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([64, 110]) from checkpoint, the shape in current model is torch.Size([64, 209]).\n\tsize mismatch for decoder.6.weight: copying a param with shape torch.Size([110, 64]) from checkpoint, the shape in current model is torch.Size([209, 64]).\n\tsize mismatch for decoder.6.bias: copying a param with shape torch.Size([110]) from checkpoint, the shape in current model is torch.Size([209]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m FP \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoEncoder(num_components, num_levels, window_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../checkpoint/autoencoder_10.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/miniconda3/envs/UniLog/lib/python3.8/site-packages/torch/nn/modules/module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AutoEncoder:\n\tsize mismatch for EmbeddingLayer.component_embedder.weight: copying a param with shape torch.Size([8, 7]) from checkpoint, the shape in current model is torch.Size([12, 11]).\n\tsize mismatch for EmbeddingLayer.level_embedder.weight: copying a param with shape torch.Size([3, 2]) from checkpoint, the shape in current model is torch.Size([8, 7]).\n\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([64, 110]) from checkpoint, the shape in current model is torch.Size([64, 209]).\n\tsize mismatch for decoder.6.weight: copying a param with shape torch.Size([110, 64]) from checkpoint, the shape in current model is torch.Size([209, 64]).\n\tsize mismatch for decoder.6.bias: copying a param with shape torch.Size([110]) from checkpoint, the shape in current model is torch.Size([209])."
     ]
    }
   ],
   "source": [
    "## Directly apply autoencoder to anomaly detection\n",
    "TOP = 0\n",
    "TON = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "model = AutoEncoder(num_components, num_levels, window_size+1).cuda()\n",
    "model.load_state_dict(torch.load('../checkpoint/autoencoder_10.pth'))\n",
    "model.eval()\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='none')\n",
    "session_dict = {}\n",
    "thresh = 0.03\n",
    "\n",
    "for batch in dataloader_test:\n",
    "    batch_size = len(batch['anomaly'])\n",
    "    batch_embedding, output = model(batch)\n",
    "    batch_loss = criterion(output, batch_embedding).mean(axis=1)\n",
    "    \n",
    "    pred = torch.lt(batch_loss, thresh).tolist()\n",
    "    is_anomaly = batch['anomaly']\n",
    "    \n",
    "    for ind in range(batch_size):\n",
    "        session_key = batch['session_key'][ind]\n",
    "        if session_key not in session_dict:\n",
    "            session_dict[session_key] = {'anomaly': False, 'matched': True}\n",
    "        session_dict[session_key]['anomaly'] |= is_anomaly[ind]\n",
    "        session_dict[session_key]['matched'] &= pred[ind]\n",
    "        \n",
    "for key, session_info in session_dict.items():\n",
    "    if session_info['anomaly']:\n",
    "        TOP += 1\n",
    "        if not session_info['matched']:\n",
    "            TP += 1\n",
    "    else:\n",
    "        TON += 1\n",
    "        if not session_info['matched']:\n",
    "            FP += 1\n",
    "                \n",
    "FN = TOP - TP\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / TOP\n",
    "F1 = 2 * precision * recall / (precision + recall)\n",
    "print(f'TOP: {TOP}, TON: {TON}, FP: {FP}, FN: {FN}, Precision: {precision: .3f}, Recall: {recall :.3f}, F1-measure: {F1: .3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e90e0672-a25f-4131-ae1c-f90b0321e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='none')\n",
    "loss = criterion(output, batch_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71bfb178-3930-497f-9162-9de7e262f8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.1385, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a7d8818-a967-4233-ab95-b114def66c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6772e-02, 2.6814e-02, 2.6704e-02, 1.0258e-01, 1.0325e-01, 2.0002e+00,\n",
       "        2.0007e+00, 3.8456e+00, 3.8460e+00, 5.9550e+00, 5.9552e+00, 6.8634e+00,\n",
       "        6.8634e+00, 7.5539e+00, 7.6425e+00, 7.6427e+00, 6.6280e+00, 6.6281e+00,\n",
       "        4.7721e+00, 4.7722e+00, 4.1142e+00, 4.1144e+00, 3.2010e+00, 3.2010e+00,\n",
       "        2.5124e+00, 2.3785e+00, 2.3778e+00, 1.5177e+00, 1.5188e+00, 1.5234e+00,\n",
       "        1.5189e+00, 5.6686e-03, 5.6032e-03, 5.1649e-06, 5.6587e-06, 2.4496e-03,\n",
       "        2.4540e-03, 9.2625e+01, 1.4530e+02, 1.4531e+02, 1.4531e+02, 1.4530e+02,\n",
       "        1.4530e+02, 1.4531e+02, 1.4531e+02, 1.4531e+02, 1.4531e+02, 1.4531e+02,\n",
       "        5.2730e+01, 5.4766e-06, 5.9373e-06, 5.2084e-06, 5.2146e-06, 5.5956e-06,\n",
       "        5.5772e-06, 5.4947e-06, 5.4557e-06, 5.9535e-06, 5.2146e-06, 5.2013e-06,\n",
       "        5.5992e-06, 5.5539e-06, 5.4766e-06, 5.9373e-06, 5.2084e-06, 5.2146e-06,\n",
       "        5.2013e-06, 5.5992e-06, 5.5539e-06, 5.4766e-06, 1.0992e-01, 1.1044e-01,\n",
       "        1.1020e-01, 1.1026e-01, 1.2302e-01, 1.5960e-01, 1.6063e-01, 1.6007e-01,\n",
       "        1.6069e-01, 1.6013e-01, 1.5846e-01, 7.3736e-02, 7.3654e-02, 7.4285e-02,\n",
       "        7.3053e-02, 1.1062e-01, 6.6531e-02, 1.1513e-01, 1.1533e-01, 1.1534e-01,\n",
       "        1.1544e-01, 1.9338e-01, 2.0440e-01, 2.1586e-01, 2.2556e-01, 2.3357e-01,\n",
       "        1.8059e-01, 1.7930e-01, 1.3145e-01, 1.4524e-01], device='cuda:0',\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5cba309c-fcae-4872-b6c8-d49e00bc3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../model/autoencoder_10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c2322b-a033-4f4f-bba3-feefc812f9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
